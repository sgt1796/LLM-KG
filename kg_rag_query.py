"""
kg_rag_query.py
================

This script demonstrates a minimal retrieval‑augmented generation (RAG)
system operating over a knowledge graph generated by ``kg_rag_demo.py``.
It takes a saved graph (in JSON format), a natural language
question, and produces two outputs:

1. A plain‑text answer synthesised from the relevant subgraph.
2. An interactive HTML visualisation of the subgraph in which the
   nodes and edges related to the question are highlighted.  The
   visualisation is generated using the `vis-network` JavaScript library
   (embedded in the HTML) rather than relying on the optional
   `pyvis` Python package.  Open the resulting HTML file in a web
   browser to explore the graph.

The retrieval step uses simple spaCy NER and POS tagging to extract
candidate keywords from the question.  Nodes in the graph whose names
contain these keywords (case‑insensitive) are considered relevant.
The subgraph is then constructed by including all immediate neighbours
of the relevant nodes.  The answer is a linearisation of the triples
in this subgraph.

Example usage:

    python kg_rag_query.py --graph graph.json \
       --question "What challenges do Rocket and Lylla face?" \
       --output_html answer.html

After running, the script prints the answer to standard output and
creates ``answer.html`` with the highlighted graph.
"""

from __future__ import annotations

import argparse
from typing import Dict, List, Set, Tuple
import json

# We avoid a dependency on networkx by implementing a simple
# dictionary‑based graph representation.  If networkx is available
# nothing prevents the user from switching to it, but this script
# operates without it.

# For the interactive visualisation we embed a small snippet of JavaScript
# using the vis-network library.  This avoids a dependency on the
# `pyvis` Python package while still producing an interactive graph in
# the output HTML.

try:
    import spacy  # type: ignore
    _SPACY_AVAILABLE = True
except ImportError:
    # If spaCy is not available, fall back to a simple keyword extractor.
    _SPACY_AVAILABLE = False


def load_graph(json_path: str) -> Dict:
    """Load a knowledge graph from a JSON or JSONL file into a simple structure.

    This function supports several schemas:

    * The original ``kg_rag_demo.py`` format where ``nodes`` is a list of
      dictionaries with ``id`` and ``name`` keys and ``triples`` is a list
      of triples referencing these IDs.
    * A simplified list of triples where each entry is a dictionary with
      ``subject`` (or ``h``), ``relation`` (or ``r``) and ``object`` (or ``t``)
      keys.  Additional fields (e.g., ``weight`` or ``sources``) are
      ignored for structural purposes but preserved in the edge
      attributes where possible.

    The returned graph has two top‑level keys:

    - ``nodes``: a set of node names (strings).
    - ``edges``: a mapping from a source node to a mapping of target
      nodes and their edge attributes.  Each inner value is a
      dictionary with keys ``weight`` (float) and ``predicates`` (a set of
      relation strings).

    Parameters
    ----------
    json_path : str
        Path to the JSON file.

    Returns
    -------
    Dict
        A graph represented as nested dictionaries.
    """
    import os
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    nodes: Set[str] = set()
    edges: Dict[str, Dict[str, Dict[str, object]]] = {}

    # Helper to update edge entries
    def _add_edge(u: str, v: str, rel: str, weight: float = 1.0) -> None:
        # Ensure node sets
        nodes.add(u)
        nodes.add(v)
        # Add edge
        if u not in edges:
            edges[u] = {}
        if v in edges[u]:
            # update weight and predicates
            edges[u][v]["weight"] += weight
            edges[u][v]["predicates"].add(rel)
        else:
            edges[u][v] = {"weight": weight, "predicates": {rel}}

    # Case 1: original format with nodes and triples referencing IDs
    if isinstance(data, dict) and "nodes" in data and "triples" in data:
        id_to_name = {}
        for node in data["nodes"]:
            # node may be dict with id/name or id only
            nid = node.get("id") if isinstance(node, dict) else None
            nm = node.get("name") if isinstance(node, dict) else None
            if nid is not None:
                id_to_name[nid] = nm or str(nid)
        for tri in data.get("triples", []):
            # Support both h/r/t and subject/relation/object
            h = tri.get("h", tri.get("subject"))
            r = tri.get("r", tri.get("relation", ""))
            t = tri.get("t", tri.get("object"))
            w = tri.get("weight", 1.0)
            if h is None or t is None:
                continue
            u = id_to_name.get(h, str(h))
            v = id_to_name.get(t, str(t))
            try:
                w = float(w)
            except Exception:
                w = 1.0
            _add_edge(u, v, str(r), w)
        return {"nodes": nodes, "edges": edges}

    # Case 2: list of triples or dict containing triples only
    triples_list: List[Dict] = []
    if isinstance(data, list):
        triples_list = data
    elif isinstance(data, dict) and "triples" in data:
        triples_list = data["triples"]  # though case 1 captured above
    else:
        raise ValueError("Unsupported graph schema: expected dict with nodes/triples or list of triples")

    for tri in triples_list:
        if not isinstance(tri, dict):
            continue
        h = tri.get("h", tri.get("subject"))
        r = tri.get("r", tri.get("relation", ""))
        t = tri.get("t", tri.get("object"))
        w = tri.get("weight", 1.0)
        if h is None or t is None:
            continue
        u = str(h)
        v = str(t)
        try:
            w = float(w)
        except Exception:
            w = 1.0
        _add_edge(u, v, str(r), w)
    return {"nodes": nodes, "edges": edges}


def extract_keywords(question: str, nlp) -> List[str]:
    """Extract potential keywords from the question.

    If spaCy is available and ``nlp`` is provided, named entities
    together with nouns and proper nouns are extracted.  Otherwise a
    simple heuristic extracts words starting with an uppercase letter
    or containing at least one capital letter.  Duplicate results are
    removed, preserving order.

    Parameters
    ----------
    question : str
        The user's question.
    nlp : Language or ``None``
        A loaded spaCy language model if available; otherwise ``None``.

    Returns
    -------
    List[str]
        A list of keywords.
    """
    keywords: List[str] = []
    if _SPACY_AVAILABLE and nlp is not None:
        doc = nlp(question)
        # Named entities
        for ent in doc.ents:
            text = ent.text.strip()
            if len(text) > 1:
                keywords.append(text)
        # Nouns and proper nouns
        for token in doc:
            if token.pos_ in {"NOUN", "PROPN"} and len(token.text.strip()) > 1:
                keywords.append(token.lemma_.strip())
    else:
        # Fallback: take any word that contains an uppercase letter
        for token in question.split():
            tok = token.strip(" .,!?:;()[]{}")
            if not tok:
                continue
            if any(c.isupper() for c in tok):
                keywords.append(tok)
    # De‑duplicate preserving order (case‑insensitive)
    seen: Set[str] = set()
    unique_keywords: List[str] = []
    for kw in keywords:
        key = kw.lower()
        if key not in seen:
            unique_keywords.append(kw)
            seen.add(key)
    return unique_keywords


def find_relevant_nodes(G: Dict, keywords: List[str]) -> List[str]:
    """Identify nodes in a dictionary‑based graph that match any of the keywords.

    A node is considered relevant if any keyword is a substring of the
    node name (case‑insensitive).

    Parameters
    ----------
    G : Dict
        The knowledge graph returned by ``load_graph``.
    keywords : List[str]
        List of keywords extracted from the question.

    Returns
    -------
    List[str]
        The names of relevant nodes.
    """
    relevant: List[str] = []
    for node in G["nodes"]:
        for kw in keywords:
            if kw.lower() in node.lower():
                relevant.append(node)
                break
    return relevant


def build_subgraph(G: Dict, seed_nodes: List[str], depth: int = 1) -> Dict:
    """Construct a subgraph containing seed nodes and their neighbours.

    For each seed node, all successors and predecessors within the
    specified depth are included.  Predecessors are determined by
    scanning inbound edges.  The returned subgraph has the same
    dictionary structure as the full graph.

    Parameters
    ----------
    G : Dict
        The full knowledge graph returned by ``load_graph``.
    seed_nodes : List[str]
        Nodes identified as relevant to the query.
    depth : int, optional
        How many hops away from the seed nodes to include.  Defaults
        to 1.

    Returns
    -------
    Dict
        A subgraph with ``nodes`` and ``edges`` keys.
    """
    nodes_to_include: Set[str] = set(seed_nodes)
    frontier: Set[str] = set(seed_nodes)
    for _ in range(depth):
        next_frontier: Set[str] = set()
        for node in frontier:
            # Successors
            next_frontier.update(G["edges"].get(node, {}).keys())
            # Predecessors: search for nodes with an edge to the current node
            for src, targets in G["edges"].items():
                if node in targets:
                    next_frontier.add(src)
        nodes_to_include.update(next_frontier)
        frontier = next_frontier
    # Build the subgraph edges
    sub_edges: Dict[str, Dict[str, Dict[str, object]]] = {}
    for src in nodes_to_include:
        if src in G["edges"]:
            for dst, attrs in G["edges"][src].items():
                if dst in nodes_to_include:
                    sub_edges.setdefault(src, {})[dst] = {
                        "weight": attrs["weight"],
                        "predicates": set(attrs["predicates"]),
                    }
    return {"nodes": nodes_to_include, "edges": sub_edges}


def generate_answer(sub_g: Dict, seed_nodes: List[str]) -> str:
    """Produce a simple textual answer from the subgraph.

    For each seed node, all outgoing edges are linearised into a
    human‑readable form: ``subject -[predicate]-> object``.  If no
    information is available for the seed nodes, a fallback message is
    returned.

    Parameters
    ----------
    sub_g : Dict
        The subgraph containing the relevant context, as returned by
        ``build_subgraph``.
    seed_nodes : List[str]
        The nodes relevant to the question.

    Returns
    -------
    str
        A synthesised answer.
    """
    lines: List[str] = []
    for node in seed_nodes:
        if node not in sub_g["nodes"]:
            continue
        neighbours = sub_g["edges"].get(node, {})
        if not neighbours:
            continue
        for nbr, attrs in neighbours.items():
            preds = attrs.get("predicates", {"related_to"})
            pred_str = "/".join(sorted(preds))
            lines.append(f"{node} -[{pred_str}]-> {nbr}")
    if lines:
        return "; ".join(lines)
    return "No relevant information found in the knowledge graph."


def visualise(sub_g: Dict, seed_nodes: List[str], html_path: str) -> None:
    """Generate an interactive HTML visualisation of the subgraph.

    This function writes an HTML file that uses the ``vis-network``
    JavaScript library to render the subgraph.  Nodes corresponding to
    the seed nodes are coloured red and drawn larger, while other nodes
    are coloured light blue.  Edges adjacent to seed nodes are coloured
    red and drawn thicker.  Clicking and dragging nodes is supported
    when the HTML file is opened in a browser.

    Parameters
    ----------
    sub_g : Dict
        The subgraph to visualise, as returned by ``build_subgraph``.
    seed_nodes : List[str]
        List of nodes considered important for highlighting.
    html_path : str
        Path to the output HTML file.
    """
    # Build node and edge dictionaries for vis-network
    node_data = []
    for node in sub_g["nodes"]:
        is_seed = node in seed_nodes
        node_data.append({
            "id": node,
            "label": node,
            "color": "red" if is_seed else "#a3c1da",
            "size": 30 if is_seed else 15
        })
    edge_data = []
    for u, targets in sub_g["edges"].items():
        for v, attrs in targets.items():
            preds = attrs.get("predicates", {"related_to"})
            label = "/".join(sorted(preds))
            is_highlight = u in seed_nodes or v in seed_nodes
            edge_data.append({
                "from": u,
                "to": v,
                "label": label,
                "color": "red" if is_highlight else "#cccccc",
                "width": 3 if is_highlight else 1
            })
    # Convert data to JSON strings
    nodes_json = json.dumps(node_data)
    edges_json = json.dumps(edge_data)
    # Build HTML with vis-network
    html = f"""
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Knowledge Graph Visualisation</title>
  <script type="text/javascript" src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
  <style>
    html, body {{ height: 100%; margin: 0; }}
    #network {{ width: 100%; height: 100%; border: 1px solid lightgray; }}
  </style>
</head>
<body>
  <div id="network"></div>
  <script type="text/javascript">
    var nodes = new vis.DataSet({nodes_json});
    var edges = new vis.DataSet({edges_json});
    var container = document.getElementById('network');
    var data = {{ nodes: nodes, edges: edges }};
    var options = {{
      interaction: {{ hover: true, multiselect: true }},
      physics: {{
        solver: 'barnesHut',
        stabilization: {{ iterations: 200 }}
      }},
      layout: {{ improvedLayout: true }}
    }};
    var network = new vis.Network(container, data, options);
  </script>
</body>
</html>
"""
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html)


def main() -> None:
    parser = argparse.ArgumentParser(description="Query a knowledge graph and visualise the relevant subgraph.")
    parser.add_argument("--graph", type=str, required=True, help="Path to the graph JSON file")
    parser.add_argument("--question", type=str, required=True, help="Question to ask the knowledge graph")
    parser.add_argument("--output_html", type=str, required=True, help="Path to save the HTML visualisation")
    args = parser.parse_args()
    # Load the knowledge graph
    G = load_graph(args.graph)
    # Load spaCy if available
    nlp = None
    if _SPACY_AVAILABLE:
        try:
            nlp = spacy.load("en_core_web_sm")  # type: ignore[name-defined]
        except Exception:
            nlp = None
    # Extract keywords from the question
    keywords = extract_keywords(args.question, nlp)
    if not keywords:
        print("No keywords were extracted from the question. Please rephrase your query.")
        return
    # Identify seed nodes in the graph
    seed_nodes = find_relevant_nodes(G, keywords)
    if not seed_nodes:
        print(f"No nodes in the graph matched the keywords: {keywords}")
        return
    # Build a subgraph around the seed nodes
    sub_g = build_subgraph(G, seed_nodes, depth=1)
    # Generate a simple answer based on the subgraph
    answer = generate_answer(sub_g, seed_nodes)
    print(answer)
    # Create an interactive visualisation
    visualise(sub_g, seed_nodes, args.output_html)
    print(f"Visualisation saved to {args.output_html}")


if __name__ == "__main__":
    main()